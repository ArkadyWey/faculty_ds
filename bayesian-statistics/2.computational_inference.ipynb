{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Inference via NumPyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want try out what we learned about computational inference and conduct the inferences we did in the previous notebook now with the use of sampling methods. We will be using the NumPyro library, to which we will do a short introduction before digging into the inference part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model specification in NumPyro\n",
    "\n",
    "As before we want to estimate the probability of a coin landing heads based on a number of observed flips. Assuming a Beta-distributed prior with parameters $\\alpha=\\beta=10$, the model has the form \n",
    "\n",
    "$$\n",
    "    \\theta \\sim \\mathrm{Beta}(10, 10) \\\\\n",
    "    y_i \\sim \\mathrm{Bernoulli}(\\theta), \\quad i = 1, \\dots, N\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 10\n",
    "BETA = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building a probabilistic model as a Python function just using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.random` to sample from distributions, e.g., from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.beta(ALPHA, BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(n=1):\n",
    "    theta = np.random.beta(ALPHA, BETA)  # prior\n",
    "    y = np.random.binomial(1, theta, size=n)  # likelihood\n",
    "    return theta, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or indeed from the model. We simply sample theta, then n samples of y given that theta and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpyro\n",
    "\n",
    "The corresponding model in NumPyro will look very similar, but instead of using distributions from `numpy.random` we use `numpyro.sample` statements and pass the corresponding distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "\n",
    "# tell numpyro to use multiple cores\n",
    "numpyro.set_host_device_count(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(n=1):\n",
    "    theta = numpyro.sample(\"theta\", dist.Beta(ALPHA, BETA))  # prior\n",
    "    y = numpyro.sample(\"y\", dist.Bernoulli(theta).expand((n,)))  # likelihood\n",
    "    return theta, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final change is that NumPyro does not maintain global random state, so we need to manually seed the model. Don't worry about why this is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from jax import random\n",
    "\n",
    "rng_key = random.PRNGKey(42)\n",
    "\n",
    "with numpyro.handlers.seed(rng_seed=rng_key):\n",
    "    theta, y = model(n=20)\n",
    "\n",
    "theta, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing models\n",
    "\n",
    "The reason for annotating variables we want to sample with numpyro.sample statements is so that NumPyro can trace the execution of the model and understand its structure for inference purposes. NumPyro actually exposes the trace handler so we can do this ourselves to see what information is captured when we run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with numpyro.handlers.seed(rng_seed=rng_key), numpyro.handlers.trace() as t:\n",
    "    theta, y = model(n=20)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the trace picks out the annotated variables, their values and a bunch of other information that might be relevant to inference algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the model\n",
    "\n",
    "We can make a few improvements to the model.\n",
    "\n",
    "- We will allow the user to pass in y values for the model to condition on. This ability to condition on observed data is crucial in order to make inferences about the latent variables ($\\theta$ in this case).\n",
    "- We will replace `.expand` with a `numpyro.plate` context manager. This NumPyro primitive is another way of specifying batch dimensions inspired by [plate notation](https://en.wikipedia.org/wiki/Plate_notation) and makes for more readble code + additional useful output in the model trace.\n",
    "- Finally we won't bother with return values, because as we can see above all of the values are captured in the model trace. Generally we only use return values in NumPyro models for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(y=None):\n",
    "\n",
    "    n = y.shape[0] if y is not None else 20\n",
    "\n",
    "    # prior\n",
    "    theta = numpyro.sample(\"theta\", dist.Beta(ALPHA, BETA))\n",
    "\n",
    "    # likelihood\n",
    "    with numpyro.plate(\"n\", n):\n",
    "        numpyro.sample(\"y\", dist.Bernoulli(theta), obs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpyro lets us create neat visualizations of our probabilistic  model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numpyro.render_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from the prior\n",
    "NumPyro provides a convenient interface for drawing multiple samples from a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 4_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Predictive(model, num_samples=N_SAMPLES)\n",
    "\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "prior_samples = prior(subkey)\n",
    "\n",
    "prior_samples[\"theta\"].shape, prior_samples[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prior_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bayesian inference via NumPyro\n",
    "\n",
    "Once we've built the model inference is pretty straight-forward. Let's fit the model to the data of our lazy 3-coin toss trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data described as 3 outcomes from Bernoulli trials\n",
    "y = np.array([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.infer import MCMC, NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mcmc = MCMC(NUTS(model), num_warmup=500, num_samples=int(N_SAMPLES / 4), num_chains=4)\n",
    "\n",
    "rng_key, subkey = random.split(rng_key)\n",
    "mcmc.run(subkey, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyro provides a summary of your MCMC sampling, including statistics on the produced samples and an MCMC diagnostic: `r_hat`. We won't go into the details of `r_hat` here but note that `r_hat=1` indicates that our chains have converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posterior_samples[\"theta\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posterior_samples[\"theta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot prior and posterior histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(np.array(posterior_samples[\"theta\"]), alpha=0.5, bins=50, label=\"posterior\")\n",
    "ax.hist(np.array(prior_samples[\"theta\"]), alpha=0.5, bins=50, label=\"prior\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare these histograms to the true pdf-plots from the previous notebook we notice they look very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Statistics\n",
    "\n",
    "#### A. Expecation value\n",
    "\n",
    "**Exercise:** Compute the Monte Carlo estimate of the expectation of $\\theta$ under the posterior. For posterior samples $\\theta_i$, $i=1, ..., N$, this estimate is defined by\n",
    "\n",
    "$$\\mathbb{E}\\left[\\theta \\vert y\\right] \\approx \\frac{1}{N}\\sum_{i=1}^N \\theta_i.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ...\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Event Probabilities\n",
    "\n",
    "Compute the Monte Carlo estimate for the probability of $\\theta \\in [\\theta_1, \\theta_2]$ under the posterior. For posterior samples $\\theta_i$, $i=1, ..., N$, this estimate is defined by,\n",
    "\n",
    "$$ \\int_{\\theta_1}^{\\theta_2} p(\\theta \\vert y) \\mathrm{d} \\theta \\approx \\frac{ \\#\\{\\theta_i \\in [\\theta_1, \\theta_2]\\} }{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice:** What's the estimated probability of the coin being fair within a tolerance of 0.025? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_fair = ...\n",
    "print(proba_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given probability $P \\in [0,1]$ the associated posterior quantile can be approximated via posterior samples $\\theta_i$, $i=1, ..., N$ by\n",
    "\n",
    "$$ \\arg\\max_x \\left\\{ \\int_0^{x} \\ p(\\theta \\vert y) d\\theta \\le P \\right\\} \\approx \\arg\\max_x \\left\\{ \\frac{1}{N}\\sum_{i=1}^N \\chi(\\theta_i \\in [0, x]) \\le P \\right\\} $$\n",
    "\n",
    "**Exercise:** What's the 5-th and 95-th percentile estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_5 = ...\n",
    "perc_95 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(perc_5)\n",
    "print(perc_95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
