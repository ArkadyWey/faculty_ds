{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paris births model\n",
    "\n",
    "Let us construct the Paris births model using Stan.\n",
    "\n",
    "We'll use `pystan`, the Python interface to Stan, and also a package called `jupyterstan`, written by former Faculty data scientist Jan Freyberg, which gives us Stan syntax highlighting inside jupyter. See below for some details on how to use `pystan` with a seperate `.stan` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arviz pystan jupyterstan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "\n",
    "%load_ext jupyterstan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEMALE_BIRTHS = 241945\n",
    "MALE_BIRTHS = 251527"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the Stan model\n",
    "\n",
    "We let $n$ denote the total number of births, $y$ the number of female births, and $p$ the underlying probability that any given baby is born female (which are assumed independent, identically distributed events). The model we are going to fit can be specified as:\n",
    "\n",
    "$$\n",
    "    \\theta \\sim \\mathrm{Unif}(0,1) \\\\\n",
    "    y | \\theta \\sim \\mathrm{Binomial}(n, \\theta)\n",
    "$$\n",
    "\n",
    "i.e. we assume that all possible values of $\\theta$ are equally likely, and that $y$ given $\\theta$ is distributed binomiall with $n$ trials and probability $\\theta$.\n",
    "\n",
    "Let's specify this model in Stan. Thanks to `jupyterstan` we can use the `%%stan` magic to specify a Stan code cell which gives us syntax higlighting. The compiled model will be saved to the `female_birth_model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stan female_birth_model\n",
    "\n",
    "data {\n",
    "    int n;  // total births\n",
    "    int y;  // female births\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0, upper=1> theta;\n",
    "}\n",
    "\n",
    "model {\n",
    "    // \n",
    "    y ~ binomial(n, theta);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hit enter on the cell above. It will take a bit of time to compile. For simple models like this the compilation time is actually much longer than the sampling time. When it's done, we should have a new `StanModel` object assigned to `female_birth_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_birth_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass our data to the model and ask it to produce samples for us using the `sampling` method of the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is passed to Stan as a dict\n",
    "data = {\n",
    "    \"n\": FEMALE_BIRTHS + MALE_BIRTHS,\n",
    "    \"y\": FEMALE_BIRTHS,\n",
    "}\n",
    "\n",
    "fit = female_birth_model.sampling(data=data, chains=4, iter=4000, n_jobs=1)\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, printing the fit object gives us basic summary stats of the sampling, such as the sample mean, mean standard error (estimated sampling error), the sample standard deviation, and various sample quantiles that let us easily see what the central 50% and 95% intervals are for each parameter (in our case, we only have one parameter p, lp__ is the log posterior which will get generated by every Stan model). In addition to summary statistic, fit displays two diagnostic metrics:\n",
    "\n",
    " * n_eff - Stan's sampling algorithm draws correlated samples, which have less statistical power than independent samples. This metric estimates how many independent draws from the posterior distribution would have the same power as the correlated samples Stan has drawn.\n",
    " * Rhat - This is a convergence metric for the sampling algorithm. If all of your chains have converged it will be 1 or very close to it. If you have Rhat greater than 1.2 you should probably investigate, if it’s greater than 2 your samples are probably no good for inference. Note that Rhat equal to 1 doesn’t actually guarantee convergence, it is a necessary condition but not sufficient.\n",
    "\n",
    "To use the sampled values themselves, run the `extract` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = fit.extract()\n",
    "\n",
    "params[\"theta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the fit\n",
    "\n",
    "Use `arviz` to easily visualise your fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az_data = az.from_pystan(posterior=fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created the `az_data` object, you can plot the sampled density of any of the parameters. The plot will be truncated at the credible interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(az_data, var_names=[\"theta\"], figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of other plots available, including a forest, which lets you easily compare chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(az_data, figsize=(12, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a trace plot, which again gives us a sense of whether the sampler converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(az_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. The average height of males in the UK is 175cm, with a standard deviation of 10cm. Use `numpy.random.normal` to generate 10 random normal samples with mean 175 and standard deviation 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = np.random.normal(loc=175, scale=10, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Suppose that we didn't know the true mean height, which we call `mu`, but we know somehow that the standard deviation is 10cm. We want to try and infer the mean from data. We decide a normal prior with mean 150 and standard deviation 50 (so that we are 99% sure that the mean is going to lie between 0cm and 3m) will be reasonably informative but not introduce too much bias. Hence our model is\n",
    "$$\n",
    "    \\mu \\sim \\mathcal{N}(150, 50^2) \\\\\n",
    "    h \\sim \\mathcal{N}(\\mu, 10^2)\n",
    "$$\n",
    "Code this model up in Stan, and then draw samples from the posterior distribution for `mu`. Plot the posterior density using `plot_density` from `arviz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stan normal_model\n",
    "data {\n",
    "  int n;\n",
    "  vector[n] h;\n",
    "}\n",
    "parameters {\n",
    "  real mu;\n",
    "}\n",
    "model {\n",
    "  mu ~ normal(150, 50);\n",
    "  h ~ normal(mu, 10);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"n\": len(samples),\n",
    "    \"h\": samples,\n",
    "}\n",
    "\n",
    "fit = normal_model.sampling(data=data, chains=4, iter=2000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Estimate the following:\n",
    "\n",
    "    a. The posterior mean of `mu`.\n",
    "    \n",
    "    b. The probability that `mu` is greater than 175cm.\n",
    "    \n",
    "    c. The 95% credible interval for `mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = fit.extract()[\"mu\"]\n",
    "\n",
    "post_mean = mu.mean()\n",
    "print(f\"The posterior mean is approx {post_mean}\")\n",
    "\n",
    "prob_geq_175 = (mu >= 175).sum() / mu.shape\n",
    "print(f\"The probability mu >= 175 is approx {prob_geq_175}\")\n",
    "\n",
    "int95 = np.percentile(mu, [2.5, 97.5])\n",
    "print(f\"95% credible interval is approx {int95}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repeat the above with a random sample of 10000 heights from $\\mathcal{N}(175, 10^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_10k = np.random.normal(175, 10, 10000)\n",
    "\n",
    "data_10k = {\n",
    "    \"n\": len(samples),\n",
    "    \"h\": samples,\n",
    "}\n",
    "\n",
    "fit_10k = normal_model.sampling(data=data, chains=4, iter=2000, n_jobs=1)\n",
    "\n",
    "mu_10k = fit_10k.extract()[\"mu\"]\n",
    "\n",
    "post_mean_10k = mu_10k.mean()\n",
    "print(f\"The posterior mean is approx {post_mean}\")\n",
    "\n",
    "prob_geq_175_10k = (mu_10k >= 175).sum() / mu.shape\n",
    "print(f\"The probability mu >= 175 is approx {prob_geq_175_10k}\")\n",
    "\n",
    "int95_10k = np.percentile(mu_10k, [2.5, 97.5])\n",
    "print(f\"95% credible interval is approx {int95_10k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit\n",
    "\n",
    "This notebook makes extensive use of PyStan which is licensed under the GPL license, a requirement of which is that derivative works are also licensed under the GPL license. Hence this notebook is distributed under the GPL license. There is a copy of the full text of the license in this directory.\n",
    "\n",
    "<hr>\n",
    "\n",
    "<small style=\"font-size:12px\">\n",
    "This notebook is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This notebook is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with Foobar.  If not, see <https://www.gnu.org/licenses/>.\n",
    "</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
